{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OONI Data Analysis - Internet Blocking Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Open Observatory of Network Interference (OONI) is a global initiative dedicated to monitoring Internet censorship and network interference. This notebook analyzes OONI data to identify instances of Internet blocking by implementing analytical techniques to assess the likelihood that observed anomalies are genuine cases of blocking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we'll load the provided CSV file and conduct an initial exploration of the dataset to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting plot styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# For better display of dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = '202505-ooni-hpi-sample.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nNumber of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of columns\n",
    "print(\"Columns in the dataset:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "df_info = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Missing Values': df.isnull().sum(),\n",
    "    'Missing Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values for categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "for col in categorical_columns[:10]:  # Limiting to first 10 columns to avoid overwhelming output\n",
    "    unique_values = df[col].nunique()\n",
    "    if unique_values < 20:  # Only show value counts for columns with fewer than 20 unique values\n",
    "        print(f\"\\n{col} - {unique_values} unique values:\")\n",
    "        print(df[col].value_counts().sort_values(ascending=False).head(10))\n",
    "    else:\n",
    "        print(f\"\\n{col} - {unique_values} unique values (too many to display)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Distribution of Data\n",
    "\n",
    "Let's examine the distribution of measurements over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's a timestamp column\n",
    "timestamp_cols = [col for col in df.columns if 'time' in col.lower() or 'date' in col.lower()]\n",
    "\n",
    "if timestamp_cols:\n",
    "    print(f\"Potential timestamp columns: {timestamp_cols}\")\n",
    "    \n",
    "    # Attempt to parse the first timestamp column\n",
    "    try:\n",
    "        time_col = timestamp_cols[0]\n",
    "        if pd.api.types.is_numeric_dtype(df[time_col]):\n",
    "            # If it's a numeric timestamp (Unix epoch)\n",
    "            df['parsed_time'] = pd.to_datetime(df[time_col], unit='s')\n",
    "        else:\n",
    "            # If it's a string timestamp\n",
    "            df['parsed_time'] = pd.to_datetime(df[time_col])\n",
    "            \n",
    "        # Plot time distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df['parsed_time'].dt.date.value_counts().sort_index().plot(kind='line')\n",
    "        plt.title('Distribution of Measurements Over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Number of Measurements')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not parse timestamp column {time_col}: {e}\")\n",
    "else:\n",
    "    print(\"No obvious timestamp columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical Distribution\n",
    "\n",
    "Let's examine the geographical distribution of the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for country or location columns\n",
    "geo_cols = [col for col in df.columns if any(term in col.lower() for term in ['country', 'location', 'geo', 'region', 'city', 'probe_cc'])]\n",
    "\n",
    "if geo_cols:\n",
    "    print(f\"Potential geographical columns: {geo_cols}\")\n",
    "    \n",
    "    # Plot distribution for the first identified geographical column\n",
    "    geo_col = geo_cols[0]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_locations = df[geo_col].value_counts().head(20)\n",
    "    sns.barplot(x=top_locations.values, y=top_locations.index)\n",
    "    plt.title(f'Top 20 {geo_col}')\n",
    "    plt.xlabel('Number of Measurements')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No obvious geographical columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results Analysis\n",
    "\n",
    "Now, let's look at the distribution of test results to start identifying potential blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for result or status columns\n",
    "result_cols = [col for col in df.columns if any(term in col.lower() for term in ['result', 'status', 'block', 'censor', 'anomaly', 'outcome'])]\n",
    "\n",
    "if result_cols:\n",
    "    print(f\"Potential result columns: {result_cols}\")\n",
    "    \n",
    "    # Analyze the first result column\n",
    "    result_col = result_cols[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df[result_col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Distribution of {result_col}')\n",
    "    plt.xlabel('Result Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No obvious result columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Initial Data Exploration\n",
    "\n",
    "Based on the initial exploration, we can summarize the following about the OONI dataset:\n",
    "\n",
    "1. **Dataset Size**: The dataset contains [to be filled after running] rows and [to be filled after running] columns.\n",
    "2. **Key Columns**: [To be identified after running]\n",
    "3. **Temporal Distribution**: [To be described after running]\n",
    "4. **Geographical Distribution**: [To be described after running]\n",
    "5. **Test Results**: [To be described after running]\n",
    "6. **Missing Data**: [To be summarized after running]\n",
    "\n",
    "In the next sections, we'll dive deeper into analyzing specific aspects of the data to identify instances of Internet blocking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
